# week4
### Lecture 7. Vanishing Gradients, Fancy RNNs (강의자 : 최혜빈) 
* Vanishing Gradient Problem 
* LSTM 
* GRU 
* More Fancy RNN Variants 

### Lecture 8. Translation, Seq2Seq, Attention (강의자 : 고경태) 
* Machine Translation 
* Sequence to Sequence 
* Neural Technique : Attention 
